{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275939b0",
   "metadata": {},
   "source": [
    "# Spellcheck LLM dengan Ollama di Google Colab\n",
    "\n",
    "Notebook ini melakukan koreksi ejaan pada kalimat Bahasa Indonesia menggunakan LLM (Ollama) dan menghitung akurasi hasil koreksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SETUP: Install dependencies dan Ollama ---\n",
    "!pip install requests Levenshtein matplotlib numpy\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "!ollama serve &\n",
    "!ollama pull llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88af691",
   "metadata": {},
   "source": [
    "## 1. Dataset & Utilitas Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpellingDataset dan contoh dataset\n",
    "class SpellingDataset:\n",
    "    def __init__(self, error_sentences=None, correct_sentences=None):\n",
    "        self.error_sentences = error_sentences or []\n",
    "        self.correct_sentences = correct_sentences or []\n",
    "    def add_sample(self, error_sentence, correct_sentence):\n",
    "        self.error_sentences.append(error_sentence)\n",
    "        self.correct_sentences.append(correct_sentence)\n",
    "    def get_all_samples(self):\n",
    "        return list(zip(self.error_sentences, self.correct_sentences))\n",
    "    def __len__(self):\n",
    "        return len(self.error_sentences)\n",
    "\n",
    "def get_sample_indonesian_dataset():\n",
    "    dataset = SpellingDataset()\n",
    "    dataset.add_sample(\"Saya Belajaaar Apa\", \"Saya Belajar Apa\")\n",
    "    dataset.add_sample(\"Dia mkan nasi goreng kemren\", \"Dia makan nasi goreng kemarin\")\n",
    "    dataset.add_sample(\"Aku prgi ke sekola tiap pagi\", \"Aku pergi ke sekolah tiap pagi\")\n",
    "    dataset.add_sample(\"Ibuku maseh memaska di dpur\", \"Ibuku masih memasak di dapur\")\n",
    "    dataset.add_sample(\"Kmaren sya bermian bola dngan teman\", \"Kemarin saya bermain bola dengan teman\")\n",
    "    dataset.add_sample(\"Bapak sdeng membersiihkan moblnya\", \"Bapak sedang membersihkan mobilnya\")\n",
    "    dataset.add_sample(\"Adik sya menangiss karna jatuh\", \"Adik saya menangis karena jatuh\")\n",
    "    dataset.add_sample(\"Kuching itu berlrai cepet sekali\", \"Kucing itu berlari cepat sekali\")\n",
    "    dataset.add_sample(\"Kakak membelii bukuu itu kemarn\", \"Kakak membeli buku itu kemarin\")\n",
    "    dataset.add_sample(\"Kami perrgi ke pantay waktu liburran\", \"Kami pergi ke pantai waktu liburan\")\n",
    "    return dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = get_sample_indonesian_dataset()\n",
    "kalimat_salah = dataset.error_sentences\n",
    "kalimat_benar = dataset.correct_sentences\n",
    "print(f\"Jumlah data: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad34f0",
   "metadata": {},
   "source": [
    "## 2. Client Ollama untuk Koreksi Ejaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class OllamaClient:\n",
    "    def __init__(self, base_url=\"http://localhost:11434\"):\n",
    "        self.base_url = base_url\n",
    "        self.api_endpoint = f\"{self.base_url}/api/generate\"\n",
    "    def correct_spelling(self, text, model=\"llama3\", system_prompt=None):\n",
    "        if system_prompt is None:\n",
    "            system_prompt = (\n",
    "                \"Anda adalah asisten yang membantu memperbaiki ejaan kalimat Bahasa Indonesia. \"\n",
    "                \"Perbaiki hanya ejaan yang salah, jangan tambahkan penjelasan atau kata lain. \"\n",
    "                \"Kembalikan hanya kalimat hasil koreksi.\"\n",
    "            )\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": text,\n",
    "            \"system\": system_prompt,\n",
    "            \"stream\": False,\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(self.api_endpoint, json=payload)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            return result[\"response\"].strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Gagal koreksi: {e}\")\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e909732",
   "metadata": {},
   "source": [
    "## 3. Fungsi Evaluasi Akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f097ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi sederhana untuk mengukur akurasi LLM\n",
    "import numpy as np\n",
    "\n",
    "def skema_exact_match(hasil_prediksi, target_benar):\n",
    "    \"\"\"\n",
    "    Skema 1: Membandingkan hasil prediksi dan target secara langsung (exact match)\n",
    "    \n",
    "    Args:\n",
    "        hasil_prediksi (list): List hasil prediksi dari LLM\n",
    "        target_benar (list): List kalimat target yang benar\n",
    "        \n",
    "    Returns:\n",
    "        float: Akurasi (0-1)\n",
    "        list: Detail hasil per item (benar/salah)\n",
    "    \"\"\"\n",
    "    if len(hasil_prediksi) != len(target_benar):\n",
    "        raise ValueError(\"Jumlah prediksi dan target harus sama\")\n",
    "        \n",
    "    hasil_per_item = [pred == target for pred, target in zip(hasil_prediksi, target_benar)]\n",
    "    akurasi = sum(hasil_per_item) / len(hasil_per_item) if hasil_per_item else 0\n",
    "    \n",
    "    return akurasi, hasil_per_item\n",
    "\n",
    "def skema_kata_per_kata(hasil_prediksi, target_benar):\n",
    "    \"\"\"\n",
    "    Skema 2: Membandingkan kata per kata antara hasil prediksi dan target\n",
    "    \n",
    "    Args:\n",
    "        hasil_prediksi (list): List hasil prediksi dari LLM\n",
    "        target_benar (list): List kalimat target yang benar\n",
    "        \n",
    "    Returns:\n",
    "        float: Rata-rata akurasi kata per kalimat (0-1)\n",
    "        list: Detail akurasi per kalimat\n",
    "    \"\"\"\n",
    "    if len(hasil_prediksi) != len(target_benar):\n",
    "        raise ValueError(\"Jumlah prediksi dan target harus sama\")\n",
    "    \n",
    "    akurasi_per_kalimat = []\n",
    "    \n",
    "    for pred, target in zip(hasil_prediksi, target_benar):\n",
    "        # Split kalimat menjadi kata-kata\n",
    "        pred_words = pred.split()\n",
    "        target_words = target.split()\n",
    "        \n",
    "        # Hitung jumlah kata yang benar\n",
    "        total_words = max(len(pred_words), len(target_words))\n",
    "        \n",
    "        if total_words == 0:\n",
    "            # Kasus khusus jika kalimat kosong\n",
    "            akurasi_kata = 1.0 if pred == target else 0.0\n",
    "        else:\n",
    "            # Hitung kata yang sama pada posisi yang sama\n",
    "            correct_words = sum(1 for i in range(min(len(pred_words), len(target_words))) \n",
    "                             if pred_words[i] == target_words[i])\n",
    "            akurasi_kata = correct_words / total_words\n",
    "        \n",
    "        akurasi_per_kalimat.append(akurasi_kata)\n",
    "    \n",
    "    # Rata-rata akurasi dari semua kalimat\n",
    "    avg_akurasi = np.mean(akurasi_per_kalimat) if akurasi_per_kalimat else 0\n",
    "    \n",
    "    return avg_akurasi, akurasi_per_kalimat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a77ee",
   "metadata": {},
   "source": [
    "## 4. Proses Koreksi Ejaan dengan LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435baa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "client = OllamaClient()\n",
    "hasil_llm = []\n",
    "processing_times = []\n",
    "\n",
    "for i, kalimat in enumerate(kalimat_salah):\n",
    "    print(f\"Input   : {kalimat}\")\n",
    "    start = time.time()\n",
    "    hasil = client.correct_spelling(kalimat)\n",
    "    end = time.time()\n",
    "    hasil_llm.append(hasil)\n",
    "    processing_times.append(end-start)\n",
    "    print(f\"Target  : {kalimat_benar[i]}\")\n",
    "    print(f\"LLM     : {hasil}\")\n",
    "    print(f\"Waktu   : {end-start:.2f}s\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c2784",
   "metadata": {},
   "source": [
    "## 5. Evaluasi & Visualisasi Akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hitung akurasi dengan kedua skema\n",
    "exact_acc, exact_detail = skema_exact_match(hasil_llm, kalimat_benar)\n",
    "kata_acc, kata_detail = skema_kata_per_kata(hasil_llm, kalimat_benar)\n",
    "\n",
    "# Tampilkan hasil akurasi\n",
    "print(f\"====== Hasil Evaluasi ======\")\n",
    "print(f\"Skema 1 - Exact Match Accuracy : {exact_acc:.4f}\")\n",
    "print(f\"Skema 2 - Word Match Accuracy  : {kata_acc:.4f}\")\n",
    "print(f\"Rata-rata waktu proses         : {np.mean(processing_times):.2f}s\")\n",
    "\n",
    "# Detail hasil per kalimat\n",
    "print(\"\\n====== Detail Hasil per Kalimat ======\")\n",
    "for i, (salah, benar, hasil, exact, kata_akurasi) in enumerate(zip(kalimat_salah, kalimat_benar, hasil_llm, exact_detail, kata_detail)):\n",
    "    status = \"✓\" if exact else \"✗\"\n",
    "    print(f\"{i+1}. {status} Kata Benar: {kata_akurasi:.2f}\")\n",
    "    print(f\"   Input : {salah}\")\n",
    "    print(f\"   Target: {benar}\")\n",
    "    print(f\"   LLM   : {hasil}\\n\")\n",
    "\n",
    "# Visualisasi\n",
    "metrics = ['Exact Match', 'Word Match']\n",
    "values = [exact_acc, kata_acc]\n",
    "colors = ['blue', 'green']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(metrics, values, color=colors)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.title('Akurasi Koreksi Ejaan dengan LLM')\n",
    "plt.ylabel('Akurasi')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Tambahkan label nilai di atas bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "            f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48009fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi detail akurasi kata per kalimat\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, len(kata_detail)+1), kata_detail, color='skyblue')\n",
    "plt.axhline(y=kata_acc, color='r', linestyle='--', label=f'Rata-rata: {kata_acc:.2f}')\n",
    "plt.xlabel('Nomor Kalimat')\n",
    "plt.ylabel('Akurasi Kata')\n",
    "plt.title('Detail Akurasi Kata per Kalimat')\n",
    "plt.xticks(range(1, len(kata_detail)+1))\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(kata_detail):\n",
    "    plt.text(i+1, v+0.02, f'{v:.2f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
