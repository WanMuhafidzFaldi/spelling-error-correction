{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275939b0",
   "metadata": {},
   "source": [
    "# Spellcheck LLM dengan Ollama di Google Colab\n",
    "\n",
    "Notebook ini melakukan koreksi ejaan pada kalimat Bahasa Indonesia menggunakan LLM (Ollama) dan menghitung akurasi hasil koreksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SETUP: Install dependencies dan Ollama ---\n",
    "!pip install requests Levenshtein matplotlib numpy\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "!ollama serve &\n",
    "!ollama pull llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88af691",
   "metadata": {},
   "source": [
    "## 1. Dataset & Utilitas Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpellingDataset dan contoh dataset\n",
    "class SpellingDataset:\n",
    "    def __init__(self, error_sentences=None, correct_sentences=None):\n",
    "        self.error_sentences = error_sentences or []\n",
    "        self.correct_sentences = correct_sentences or []\n",
    "    def add_sample(self, error_sentence, correct_sentence):\n",
    "        self.error_sentences.append(error_sentence)\n",
    "        self.correct_sentences.append(correct_sentence)\n",
    "    def get_all_samples(self):\n",
    "        return list(zip(self.error_sentences, self.correct_sentences))\n",
    "    def __len__(self):\n",
    "        return len(self.error_sentences)\n",
    "\n",
    "def get_sample_indonesian_dataset():\n",
    "    dataset = SpellingDataset()\n",
    "    dataset.add_sample(\"Saya Belajaaar Apa\", \"Saya Belajar Apa\")\n",
    "    dataset.add_sample(\"Dia mkan nasi goreng kemren\", \"Dia makan nasi goreng kemarin\")\n",
    "    dataset.add_sample(\"Aku prgi ke sekola tiap pagi\", \"Aku pergi ke sekolah tiap pagi\")\n",
    "    dataset.add_sample(\"Ibuku maseh memaska di dpur\", \"Ibuku masih memasak di dapur\")\n",
    "    dataset.add_sample(\"Kmaren sya bermian bola dngan teman\", \"Kemarin saya bermain bola dengan teman\")\n",
    "    dataset.add_sample(\"Bapak sdeng membersiihkan moblnya\", \"Bapak sedang membersihkan mobilnya\")\n",
    "    dataset.add_sample(\"Adik sya menangiss karna jatuh\", \"Adik saya menangis karena jatuh\")\n",
    "    dataset.add_sample(\"Kuching itu berlrai cepet sekali\", \"Kucing itu berlari cepat sekali\")\n",
    "    dataset.add_sample(\"Kakak membelii bukuu itu kemarn\", \"Kakak membeli buku itu kemarin\")\n",
    "    dataset.add_sample(\"Kami perrgi ke pantay waktu liburran\", \"Kami pergi ke pantai waktu liburan\")\n",
    "    return dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = get_sample_indonesian_dataset()\n",
    "kalimat_salah = dataset.error_sentences\n",
    "kalimat_benar = dataset.correct_sentences\n",
    "print(f\"Jumlah data: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad34f0",
   "metadata": {},
   "source": [
    "## 2. Client Ollama untuk Koreksi Ejaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class OllamaClient:\n",
    "    def __init__(self, base_url=\"http://localhost:11434\"):\n",
    "        self.base_url = base_url\n",
    "        self.api_endpoint = f\"{self.base_url}/api/generate\"\n",
    "    def correct_spelling(self, text, model=\"llama3\", system_prompt=None):\n",
    "        if system_prompt is None:\n",
    "            system_prompt = (\n",
    "                \"Anda adalah asisten yang membantu memperbaiki ejaan kalimat Bahasa Indonesia. \"\n",
    "                \"Perbaiki hanya ejaan yang salah, jangan tambahkan penjelasan atau kata lain. \"\n",
    "                \"Kembalikan hanya kalimat hasil koreksi.\"\n",
    "            )\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": text,\n",
    "            \"system\": system_prompt,\n",
    "            \"stream\": False,\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(self.api_endpoint, json=payload)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            return result[\"response\"].strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Gagal koreksi: {e}\")\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e909732",
   "metadata": {},
   "source": [
    "## 3. Fungsi Evaluasi Akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f097ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "import numpy as np\n",
    "\n",
    "def exact_match_accuracy(predicted_texts, ground_truth_texts):\n",
    "    correct_count = sum(1 for p, g in zip(predicted_texts, ground_truth_texts) if p == g)\n",
    "    return correct_count / len(predicted_texts) if len(predicted_texts) > 0 else 0\n",
    "\n",
    "def character_level_accuracy(predicted_texts, ground_truth_texts):\n",
    "    accuracies = []\n",
    "    for pred, gt in zip(predicted_texts, ground_truth_texts):\n",
    "        distance = Levenshtein.distance(pred, gt)\n",
    "        max_length = max(len(pred), len(gt))\n",
    "        accuracy = 1 - (distance / max_length) if max_length > 0 else 1\n",
    "        accuracies.append(accuracy)\n",
    "    return np.mean(accuracies) if accuracies else 0\n",
    "\n",
    "def word_level_accuracy(predicted_texts, ground_truth_texts):\n",
    "    accuracies = []\n",
    "    for pred, gt in zip(predicted_texts, ground_truth_texts):\n",
    "        pred_words = pred.split()\n",
    "        gt_words = gt.split()\n",
    "        correct_words = sum(1 for p, g in zip(pred_words, gt_words) if p == g)\n",
    "        total_words = max(len(pred_words), len(gt_words))\n",
    "        accuracy = correct_words / total_words if total_words > 0 else 1\n",
    "        accuracies.append(accuracy)\n",
    "    return np.mean(accuracies) if accuracies else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a77ee",
   "metadata": {},
   "source": [
    "## 4. Proses Koreksi Ejaan dengan LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435baa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "client = OllamaClient()\n",
    "hasil_llm = []\n",
    "processing_times = []\n",
    "\n",
    "for i, kalimat in enumerate(kalimat_salah):\n",
    "    print(f\"Input   : {kalimat}\")\n",
    "    start = time.time()\n",
    "    hasil = client.correct_spelling(kalimat)\n",
    "    end = time.time()\n",
    "    hasil_llm.append(hasil)\n",
    "    processing_times.append(end-start)\n",
    "    print(f\"Target  : {kalimat_benar[i]}\")\n",
    "    print(f\"LLM     : {hasil}\")\n",
    "    print(f\"Waktu   : {end-start:.2f}s\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c2784",
   "metadata": {},
   "source": [
    "## 5. Evaluasi & Visualisasi Akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "exact_acc = exact_match_accuracy(hasil_llm, kalimat_benar)\n",
    "char_acc = character_level_accuracy(hasil_llm, kalimat_benar)\n",
    "word_acc = word_level_accuracy(hasil_llm, kalimat_benar)\n",
    "\n",
    "print(f\"Exact Match Accuracy     : {exact_acc:.4f}\")\n",
    "print(f\"Character-level Accuracy : {char_acc:.4f}\")\n",
    "print(f\"Word-level Accuracy      : {word_acc:.4f}\")\n",
    "print(f\"Rata-rata waktu proses   : {np.mean(processing_times):.2f}s\")\n",
    "\n",
    "# Visualisasi\n",
    "metrics = ['Exact Match', 'Character-level', 'Word-level']\n",
    "values = [exact_acc, char_acc, word_acc]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(metrics, values, color=['blue', 'green', 'orange'])\n",
    "plt.ylim(0, 1.0)\n",
    "plt.title('LLM Spelling Correction Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.02, f'{v:.2f}', ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48009fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
